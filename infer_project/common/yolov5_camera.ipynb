{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "961d4408-e2e4-40aa-ba39-065b77a161db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25d0e406b304d4fa7ad7b573c02d5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpg', height='720', width='1280')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import base64\n",
    "import datetime\n",
    "import threading\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from cameracapture import CameraCapture\n",
    "import presenteragent.presenter_channel as presenter_channel\n",
    "\n",
    "from util.acl_net import Net\n",
    "from om_infer import read_class_names, coco80_to_coco91_class, letterbox, draw_bbox\n",
    "\n",
    "FLAG = True\n",
    "\n",
    "neth, netw = 640, 640\n",
    "imgh, imgw = 720, 1280\n",
    "# https://blog.csdn.net/liuqixuan1994/article/details/88715454\n",
    "imgbox = widgets.Image(format='jpg', height=imgh, width=imgw)\n",
    "display(imgbox)\n",
    "\n",
    "def main():\n",
    "    ground_truth_json = '/home/HwHiAiUser/sample/dataset/annotations/instances_val2017.json'\n",
    "    coco_names = read_class_names(ground_truth_json)\n",
    "    coco91class = coco80_to_coco91_class()\n",
    "    device_id = 0\n",
    "    model_path = '/home/HwHiAiUser/sample/yolov5/output/yolov5s_v6.1_sim_nms_bs1.om'\n",
    "    model = Net(device_id=device_id, model_path=model_path)\n",
    "\n",
    "    cap = CameraCapture(0)\n",
    "    \n",
    "    while FLAG:\n",
    "        # Read a picture from the camera\n",
    "        image = cap.read()  # YUV420SP NV12 8bit\n",
    "        if image is None:\n",
    "            print(\"Get memory from camera failed\")\n",
    "            break\n",
    "        \n",
    "        image = image.byte_data_to_np_array()\n",
    "        image = image.astype(np.uint8)\n",
    "        image = image.reshape(-1, 1280)  # (int(imgh * 3 / 2) , imgw)\n",
    "\n",
    "        # img_rgb = cv2.cvtColor(image, cv2.COLOR_YUV2RGB_NV12)  # 模型推理的输入需要RGB格式  \n",
    "        img_bgr = cv2.cvtColor(image, cv2.COLOR_YUV2BGR_NV12) # widgets.Image 显示的时候需要BGR格式\n",
    "        \n",
    "        imgh, imgw = 720, 1280\n",
    "        imginfo = np.array([neth, netw, imgh, imgw], dtype=np.float16)\n",
    "        img_padding = letterbox(img_bgr, new_shape=(neth, netw))[0]  # padding resize   bgr\n",
    "        \n",
    "        img0 = []\n",
    "        img = []\n",
    "        img_info = []\n",
    "        \n",
    "        img0.append(img_bgr)\n",
    "        img.append(img_padding)\n",
    "        img_info.append(imginfo)\n",
    "        img = np.stack(img, axis=0)\n",
    "        img_info = np.stack(img_info, axis=0)\n",
    "        img = img[..., ::-1].transpose(0, 3, 1, 2)  # BGR tp RGB\n",
    "        image_np = np.array(img, dtype=np.float32)\n",
    "        image_np_expanded = image_np / 255.0\n",
    "        img = np.ascontiguousarray(image_np_expanded).astype(np.float16)\n",
    "        \n",
    "        result, dt = model([img, imginfo])  # net out, infer time\n",
    "        batch_boxout, boxnum = result\n",
    "\n",
    "        img0_list = img0\n",
    "        valid_num = 1 # 如果模型是可以批输入的，valid_num代表这批图像当中有效的图像张数，比如batchsize=4，可能出现只有3张的图，凑不够一批的情况\n",
    "        for idx in range(valid_num):\n",
    "            num_det = int(boxnum[idx][0])\n",
    "            boxout = batch_boxout[idx][:num_det * 6].reshape(6, -1).transpose().astype(np.float32)  # 6xN -> Nx6\n",
    "            \n",
    "            img_dw = draw_bbox(boxout, img0_list[idx], (0, 255, 0), 2, coco_names)\n",
    "            t1 = time.time() \n",
    "            imgbox.value = cv2.imencode('.jpg', img_dw)[1].tobytes()\n",
    "            t2 = time.time()\n",
    "            \n",
    "thread1 = threading.Thread(name='t1',target=main, args=())\n",
    "thread1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d185bd6-1b34-4687-ad7f-09a40238b1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Close camera 0\n"
     ]
    }
   ],
   "source": [
    "global FLAG\n",
    "FLAG = False\n",
    "thread1.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9319e7b-6b0f-4165-8356-9aa10ce0b1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
